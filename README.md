# Polynomial Regression Example ðŸš€

This project shows how **polynomial regression** can perform better than simple linear regression when data has a curved relationship.

## ðŸ“‚ Dataset
- Source: [Kaggle - Polynomial Regression Dataset](https://www.kaggle.com/datasets/mirajdeepbhandari/polynomial-regression)

## ðŸ“Œ Steps in the Project
1. **Imported libraries**:  
   `numpy`, `pandas`, `matplotlib`, `sklearn`, `kagglehub`, `os`

2. **Data Cleaning**:  
   - Checked for null values  
   - Checked for duplicates  
   - Checked data types  

3. **Data Visualization**:  
   - Plotted the data  
   - Found that there is **1 feature and 1 target**  
   - Relationship looked **parabolic (curve-shaped)**  

## ðŸ”Ž Linear Regression Attempt
- Split data into train and test sets  
- Trained a **Simple Linear Regression** model  
- **RÂ² Score:** `-0.13` (worse than the mean line ðŸ˜…)  
- The line was straight, touching some points but missing most others  

## ðŸ”„ Polynomial Regression Attempt
- Created **Polynomial Features (degree = 2)**  
- Transformed training and testing sets  
- Trained the regression model again  
- **RÂ² Score:** `0.91` ðŸŽ‰  
- Plotted the curve â†’ much better fit!  

## âœ… Conclusion
- Linear regression didnâ€™t work well because the data was curved  
- Polynomial regression (degree 2) gave a great fit with an RÂ² score of **0.91**  
- This shows why choosing the right model matters!  

---
ðŸ’¡ This project is a simple example for learning regression techniques.
